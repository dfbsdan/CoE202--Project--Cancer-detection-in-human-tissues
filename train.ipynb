{"cells":[{"cell_type":"markdown","metadata":{"id":"9sJsFHWS7gKS"},"source":["**KAIST, Fall 2020**   \n","**[CoE202(A)] Fundamentals of Artificial Intelligence**\n","\n","**Final Project: Cancer Classifier**\n","\n","**Instructor: Prof. Young-Gyu Yoon**\n"]},{"cell_type":"markdown","metadata":{"id":"HnLqUkGH1MTK"},"source":["**1. Setup.**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7464,"status":"ok","timestamp":1608041637415,"user":{"displayName":"Daniel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghd7UfyKFQdiyiFI5cfJLolcFD-rK9hVO8Ew5MQzw=s64","userId":"01727639231631830473"},"user_tz":-540},"id":"rt8VdnTN7LaE","outputId":"2db6183b-f5f2-48ad-ac84-86f532202796"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","replace train/1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n","\n","Train set size: 3686, Validation set size: 410\n","\n","['train/2401.jpg', 'train/2154.jpg', 'train/1429.jpg'] \n","       # Id  Values\n","2400  2401       0\n","2153  2154       1\n","1428  1429       1\n","['train/3206.jpg', 'train/320.jpg', 'train/3222.jpg'] \n","       # Id  Values\n","3205  3206       0\n","319    320       0\n","3221  3222       0\n","<class 'torch.Tensor'>\n","torch.Size([32, 3, 256, 256])\n"]}],"source":["##### External Libraries\n","import os\n","import time\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import datetime\n","import math\n","import sys\n","\n","!rm /etc/localtime\n","!ln -s /usr/share/zoneinfo/Asia/Seoul /etc/localtime\n","\n","##### Mount drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","##### Own libraries\n","filepath = \"/content/drive/My Drive/CoE202/proj/src\"\n","sys.path.append(filepath)\n","\n","from util import calc_accuracy, cancer_dataset, validation_sampler\n","from model_baseline import cancer_classifier, Trainer\n","from visualize import visualizer_firstlayer, visualizer\n","\n","##### Load data\n","!cp -r \"{filepath}/train.zip\" .\n","!unzip -q train.zip\n","!cp \"{filepath}/train_label.csv\" .\n","\n","##### define training parameters\n","# global parameters\n","batch_sz = 32 # batch size\n","training_p = 0.90 # % of the data for training.\n","experiment = \"results\"  # Save folder of model\n","train_ep = 10 # number of times the whole process is repeated, including data load\n","load_model = True # true: load best pre-trained model, false: train from scratch\n","visualize = False # true: visualize results, false otherwise\n","\n","# Trainer-specific parameters\n","population_size = 30\n","fitness_eval = 1000 # max allowed fitness evaluations\n","offsprings = 0.3 # percentage of parents to be replaced on each generation\n","k = 0.4 # percentage of parents to be sampled for tournament selection\n","mut = 0.1 # mutation probability of a NN layer\n","max_depth = 15 # max allowed NN depth\n","epochs = 5\n","timeout = 60 * 10 # timeout (in minutes)\n","loss_criterion = nn.CrossEntropyLoss().cuda()\n","acc_criterion = calc_accuracy\n","\n","##### Setup the training environment\n","n_train = math.floor(training_p*4096) \n","n_val = 4096 - math.floor(training_p*4096)\n","print(f\"\\nTrain set size: {n_train}, Validation set size: {n_val}\\n\")\n","\n","if not os.path.exists(f\"{filepath}/{experiment}\"):\n","    os.mkdir(f\"{filepath}/{experiment}\")\n","if not os.path.exists(f\"{filepath}/{experiment}/visualize\"):\n","    os.mkdir(f\"{filepath}/{experiment}/visualize\")\n","\n","##### Print some sample images\n","def sample_print(train_loader):\n","  (sample_batch, sample_label) = next(iter(train_loader))\n","  fig = plt.figure(figsize=(12, 12))\n","  for i in range(4):\n","    for j in range(4):\n","      fig.add_subplot(4, 4, (i * 4 + j + 1))\n","      plt.imshow(sample_batch[i*4+j].permute(1, 2, 0))\n","      plt.title(f\"label : {sample_label[i*4+j]}\")\n","  plt.suptitle(\"Sample images\")"]},{"cell_type":"markdown","metadata":{"id":"EWspL_eW-cj-"},"source":["**2. Training.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3lv8dUzg-j0X"},"outputs":[],"source":["for _ in range(train_ep):\n","  ##### dataset creation\n","  train_idx, valid_idx = validation_sampler(root=f\"train\", length_list=[n_train, n_val])\n","  train_dataset = cancer_dataset(root=f\"train\", csv=f\"train_label.csv\",\n","                                train_test=\"train\",\n","                                idx=train_idx,\n","                                transform=transforms.Compose([\n","                                transforms.ToTensor()\n","                              ]))\n","  valid_dataset = cancer_dataset(root=f\"train\", csv=f\"train_label.csv\",\n","                                train_test=\"valid\",\n","                                idx=valid_idx,\n","                                transform=transforms.Compose([\n","                                transforms.ToTensor()\n","                              ]))\n","  train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                            batch_size=batch_sz,\n","                                            shuffle=True,\n","                                            drop_last=True\n","                                            )\n","  valid_loader = torch.utils.data.DataLoader(valid_dataset,\n","                                            batch_size=batch_sz,\n","                                            shuffle=False,\n","                                            drop_last=True\n","                                            )\n","  #sample_print(train_loader)\n","\n","  ##### Train\n","  trainer = Trainer(population_size, fitness_eval, offsprings, k, mut, max_depth, epochs, \n","                    timeout, train_loader, valid_loader, loss_criterion, acc_criterion)\n","\n","  if load_model:  # Load saved model\n","    model = cancer_classifier(f\"{filepath}/{experiment}/model_state_dict.pt\")\n","    trainer.train_classifier(model)\n","  else:           # Train from scratch\n","    model = trainer.train()\n","\n","  ##### Store results\n","  model.save(f\"{filepath}/{experiment}\", \"model_state_dict\")\n","  print(\"Successfully saved.\")\n","\n","  ##### Print results\n","  print(\"Trained model:\")\n","  print(model)\n","  print(f\"Accuracy: {model.accuracy}\")"]},{"cell_type":"markdown","metadata":{"id":"Mr97W1pt0n9D"},"source":["**3. Visualization.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a2zN6jj_0knN"},"outputs":[],"source":["if visualize:\n","  print(\"\\nAfter Training!\")\n","  print(\"Visualizing overall layers (after training)\")\n","  visualizer(model, suptitle=\"\", grayscale=True, n_kernel_coefficient=256, skip_1x1=False,\n","              plt_save=f\"{filepath}/{experiment}/visualize/all_layer_after.png\", plt_show=True)\n","  print(\"Visualizing only the first layer (after training)\")\n","  visualizer_firstlayer(model, skip_1x1=False, grayscale=True, memo=\"First layer\",\n","                        plt_save=f\"{filepath}/{experiment}/visualize/1st_layer_after.png\",\n","                        plt_show=True)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNEa1d7Ec6J8+U5It4rSkIC","collapsed_sections":[],"name":"train.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
